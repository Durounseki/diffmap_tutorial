{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collective Animal Behavior and Diffusion Maps\n",
    "\n",
    "## Introduction\n",
    "\n",
    "The traditional understanding of physical systems has been heavily influenced by the notion that symmetry dictates the organization of matter within the universe. However, the recent surge in quantitative measurements and analyses across a wide range of complex systems—including living organisms and social networks—is challenging this long-held intuition.  While complex systems obey the same fundamental laws as classical matter, they are distinguished by their large number of heterogeneous components which interact through non-trivial rules and more importantly they are typically out of thermodynamic equilibrium, which rules out the use of conservation laws to study the evolution of such systems.\n",
    "\n",
    "Despite their complexity, biological systems often exhibit low-dimensional dynamics, as exemplified in cases of collective behavior, where the collective state evolves on timescales longer than individual interactions. However, identifying the relevant order parameters governing these collective states is not always straightforward. In some cases, statistical moments of microscopic variables, such as average orientation in flocking systems, can serve as order parameters. However, in many biological systems, the transitions are not driven by changes in the statistical moments but instead arise from modifications in the underlying interaction network topology due to aging, external stimuli, or changes in the ecological context.\n",
    "\n",
    "In the absence of clear symmetries, identifying the appropriate coarse-grained variables for a collective system remains a difficult task. Traditional approaches often rely on intuition or specific knowledge of the underlying biological processes, making them system-specific and inefficient.  Machine learning (ML) offers a promising alternative, with its ability to detect patterns in large datasets and extract relevant features.  While ML has seen success in various fields, including image and speech recognition, protein folding, and even many-body physics, its application to biological systems remains relatively unexplored, with only a few examples using artificial datasets.  In this tutorial, we leverage diffusion maps, an unsupervised ML technique for manifold learning and dimensionality reduction, to systematically identify the coarse-grained dynamics and potential order parameters in biological collective systems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method\n",
    "We consider the evolution of a collection of interacting particles, $A=\\{a_i\\}_{i=1}^{n}$, as a dynamical system. Each experimental observation of $A$, yields a state vector $X(t)=\\left(x_1(t), x_2(t),\\ldots, x_n(t) \\right)$, where the features $x_i(t)$ represent measurements specific to the system under study. These measurements might encompass, for instance, the position and the velocity, $x_i = (\\mathbf{x}_i,\\mathbf{v}_i)$, of the $i$-th bird in a flock of starlings or the activity of the $i$-th neuron in a neural network. Subsequent observations of $A$ generate a discrete time series $\\mathcal{X}=\\left\\{X_i\\right\\}_{i=1}^{N}=\\left\\{X(t_i)\\right\\}_{i=1}^{N}$, that represents a sampling of a trajectory in the associated phase space $\\mathcal{S}$ [see Fig.1(a)]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure style=\"display: flex; flex-direction:column; justify-content: center; align-items: center; gap: 20px\">\n",
    "    <img style=\"width: 16cm; background-color: white\" src = \"./method01_1.png\" />\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Figure 1. Dynamical systems interpretation of the collective behavior of a system of interacting particles $A$. (a) An experimental observation of $A$ at a given time $t$ is represented by the feature vector $X(t)$. Here, we use schooling juvenile zebra fish (\\textit{D. rerio}) as an illustration. In this case, the feature vectors consist of the positions and velocities of each individual in $A$, that is $x_i=(\\mathbf{x}_i, \\mathbf{v}_i)$. (b) In the presence of a collective state, the state space $\\mathcal{S}$ contains structures such as $K_+$ and $K_-$ which correspond to swirling states with positive and negative angular momentum in the case of the schooling fish. The density of states is highly concentrated around the attractors $X_\\pm$. This allows us to use clustering techniques to identify the collective states $K_\\pm$ with positive and negative angular momentum. The background color gradient represents the density of states in $\\mathcal{S}$, it is higher around the attractors $X_{\\pm}$ and negligible around the isotropic configurations with random orientations, for example $X_0$ and $\\tilde{X}_0$.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The figure above shows configurations of a group of juvenile zebra fish at different times. In this case $a_i$ represents the $i$-th fish in the group and the state vector consists of all their positions and velocities at a given time, that is $x_i = (\\mathbf{x}_i, \\mathbf{v}_i)$. The data was provided by [cite] who studied the application of machine vision to track individuals in groups of zebra fish. We replaced missing values in the tracked data using a cubic spline interpolator and we calculate the velocity using a noisy derivative scheme of fifth order [cite]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's import the curated data\n",
    "import csv\n",
    "\n",
    "def readData(source):\n",
    "    data=[]\n",
    "    '''\n",
    "    The data is in the format\n",
    "    [x11,y11], [x12,y12], ...\n",
    "    [x21,y21], [x22,y22], ...\n",
    "    ...\n",
    "    [xn1,yn1], [xn2,yn2] ...\n",
    "    '''\n",
    "    with open(source, newline='') as csvfile:\n",
    "        reader = csv.reader(csvfile,delimiter=',')\n",
    "        \n",
    "        for row in reader:\n",
    "            row_data = []\n",
    "            for i in range(0, len(row), 2):  # Process pairs\n",
    "                x = float(row[i].strip(\"[]\"))\n",
    "                y = float(row[i+1].strip(\"[]\"))\n",
    "                row_data.append([x, y])\n",
    "            data.append(row_data)\n",
    "        \n",
    "        return data\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "positions = readData('./fish-positions-100.csv')\n",
    "velocities = readData('./fish-velocities-100.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's transform these to numpy arrays so that we can manipulate them more easily\n",
    "import numpy as np\n",
    "np_pos = np.array(positions)\n",
    "np_vel = np.array(velocities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To imbue $\\mathcal{S}$ with a metric structure, we define a distance function between states $X\\in\\mathcal{S}$. While the Euclidean distance $d^2(X,\\tilde{X})=|X-\\tilde{X}|^2=\\sum_i{(x_{i}-\\tilde{x}_{i})^2}$ is a natural choice, it may be inappropriate if the system exhibits symmetries. In such cases, similar states could be erroneously separated by large distances within $\\mathcal{S}$. To address this, we preprocess the data leveraging symmetry-invariant features. Specifically, for the symmetry transformation $T$, we construct feature vectors $Y=\\left(y_1, y_2,\\ldots, y_m \\right)$ using a suitable transformation $F$, such that $y_i=F(Tx_1,Tx_2,\\ldots,Tx_n)=F(x_1,x_2,\\ldots,x_n)$. This transformation yields a modified representation of the state space, denoted as $\\mathcal{S}_Y$, wherein the Euclidean distance $|Y-\\tilde{Y}|$ can reliably quantify the similarity between states [see Fig.2].\n",
    "\n",
    "The fish data set is invariant under relabeling of the individuals, therefore we need to choose features that are invariant under permutations of the positions and velocities. The easiest option is to take the statistical moments of the configurations. This might seem like cheating, but note that we still haven't made any assumption about the nature of the system, these purely an argument about data. We also need to take care of the fact that we are mixing physical dimensions (length, velocity), we can take care of this by scaling the positions and velocities by the size of the tank and the maximum velocity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_data(data_array):\n",
    "    \"\"\"Normalizes each coordinate within each row of a 3D array to the range [-1, 1].\n",
    "\n",
    "    Args:\n",
    "        data_array: A NumPy array of shape (num_rows, num_points, 2) representing x,y coordinates.\n",
    "\n",
    "    Returns:\n",
    "        A NumPy array of the same shape as data_array, but with values normalized to [-1, 1].\n",
    "    \"\"\"\n",
    "    normalized_data = np.zeros_like(data_array)  # Create an array of the same shape\n",
    "\n",
    "    for i, row in enumerate(data_array):\n",
    "        min_vals = np.min(row, axis=0)  # Find min for each coordinate in the row\n",
    "        max_vals = np.max(row, axis=0)  # Find max for each coordinate in the row\n",
    "\n",
    "        # Normalize each coordinate to [0, 1]\n",
    "        normalized_row = (row - min_vals) / (max_vals - min_vals)  \n",
    "\n",
    "        # Scale and shift to [-1, 1]\n",
    "        normalized_data[i] = 2 * normalized_row - 1  \n",
    "\n",
    "    return normalized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_pos = normalize_data(np_pos)\n",
    "normalized_vel = normalize_data(np_vel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's combine the positions and velocities\n",
    "xv_features = np.array([np.concatenate((row1, row2), axis=1) for row1, row2 in zip(normalized_pos, normalized_vel)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we calculate the moments at each time step\n",
    "def calculate_moments(data_array):\n",
    "    \"\"\"\n",
    "    Calculates the mean and covariance matrix for each row of a 3D array.\n",
    "\n",
    "    Args:\n",
    "        data_array: A NumPy array with shape (num_rows, num_points, 4) where the last dimension \n",
    "                    represents (x, y, u, v) coordinates.\n",
    "\n",
    "    Returns:\n",
    "        A NumPy array with shape (num_rows, 14) where each row contains the mean of x, y, u, v, \n",
    "        and the unique elements of the covariance matrix.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    for row in data_array:\n",
    "\n",
    "        # Calculate mean and covariance\n",
    "        meanZ = np.mean(row, axis=0)  \n",
    "        covZ = np.cov(row, rowvar=False) \n",
    "\n",
    "        # Extract and flatten results\n",
    "        moments = np.concatenate((meanZ, covZ[np.triu_indices(covZ.shape[0])])) \n",
    "        results.append(moments)\n",
    "    return np.array(results)\n",
    "\n",
    "moment_features = calculate_moments(xv_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intuitively, when the collection $A$ develops a collective state, we expect the existence of atracttors or slow manifolds in $\\mathcal{S}$. If the trajectories are sampled at a fixed frame-rate $\\tau=t_{i+1}-t_i$, then the density of states will be higher around the attractors or along the slow manifolds [Fig.1(b)]. In such a case, dimensionality reduction techniques, such as PCA, $k$-means, UMAP, or spectral clustering, can be employed to identify the attractors. Among these techniques, spectral clustering through diffusion maps offers a distinct advantage: the eigenfunctions of the diffusion map can be interpreted as the slow variables of the system. To support this claim, consider the following argument:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure style=\"display: flex; flex-direction:column; justify-content: center; align-items: center; gap: 20px\">\n",
    "    <img style=\"width: 16cm; background-color: white\" src = \"./method02.png\" />\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Construction of the transition matrix for the diffusion process. (a) When we use the naive feature vectors, $X(t)$, together with the euclidean distance $|X-\\tilde{X}|$,the representation $\\mathcal{S}_X$ of the state spaces yields erroneously large distances between two equivalent states. For instance, the vectors $X_i = (x_1(t_i), x_2(t_i),\\ldots,x_n(t_i))$ and $X'_i = (x_{\\sigma(1)}(t_i),x_{\\sigma(2)}(t_i),\\ldots,x_{\\sigma(n)})$, where $\\sigma$ is a permutation of the set $\\{1,2,\\ldots,n\\}$ represent the same configuration of schooling zebra fish, however this are far away from each other in $\\mathcal{S}_X$. (b) To address symmetries, we use symmetry-invariant feature vectors $Y_i = F(X_i)$ that yield the representation $\\mathcal{S}_Y$ where $Y_i$ and $Y'_i$ represent the same state. On $\\mathcal{S}_Y$ we construct a fully connected graph $\\mathcal{G}_Y$ with vertices $Y_i$ and edges with weights $p^{\\epsilon}_{i,j}$ which depend on the distance $d_{i,j} = |Y_i-Y_j|$ through the Gaussian kernel $K_{\\epsilon}(d) = \\mathcal{N}e^{-d^2/\\epsilon}$, where $\\mathcal{N}$ is a normalization factor. The adjacency matrix of $\\mathcal{G}_Y$, given by $P_{\\epsilon} = p^{\\epsilon}_{i,j}$ is called the transition probability matrix and it defines a fictitious diffusion process on $\\mathcal{S}_Y$ with diffusivity $\\epsilon$. Intuitively, two states will have a high probability of transitioning into each other if their distance is less than the diffusion length $\\epsilon\\Delta t$.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The diffusion map is generated through a fictitious discrete hopping process on a complete graph $\\mathcal{G}_Y$ with vertices $Y_i$. Each edge of this graph is weighted according to a symmetric kernel $K(d_{i,j})=K(d(Y_i,Y_j))$ and the row-column normalized adjacency matrix of the weighted graph can be interpreted as a transition probability matrix $\\mathbf{P}$, with each entry $p^{\\epsilon}_{ij}\\propto \\exp{(-d_{i,j}^2/\\epsilon)}$ representing the hopping rate between $Y_i$ and $Y_j$ (for details see [cite])."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that distributions on the data space (the vertices of the graph) are represented by vectors $\\mathbf{v}\\in\\mathbb{R}^{N}$, such that $\\sum_i{v_i}=1$. Therefore a data point $Y_i$ can be represented by the canonical vector $\\mathbf{e}_i\\in\\mathbb{R}^{N}$ with entries $e_{i,j}=\\delta_{ij}$, where $\\delta_{ij}$ is the Kroenecker delta. Working under the assumption that the real trajectories are smooth, we should expect $Y_i$ and $Y_{i+1}$ to be close so that the trajectory $\\mathcal{Z}_i=\\{Z_{i}^{j}|Z_{i}^{j}\\sim P^{j}\\mathbf{e}_i\\}_{j=0}^{m}$ approximates the real trajectory $\\mathcal{Y}_i=\\{Y_{i+j}\\}_{j=0}^{m}$ [see Fig.3(c)]. Here we use, $\\sim$, to denote \"distributed according to\", in other words $Z_{i}^{j}$ is sampled from the distribution $P^{j}\\mathbf{e}_i$. Since points close together have a higher transition probability, the trajectories $\\mathcal{Z}$, generated through repeated application of $P$, will linger around the attractors for long periods of time. To complete the argument, we need to show that the eigenvectors are slow variables of the fictitious diffusion process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that the transition rate between data points decays exponentially with increasing distance $d$, we can relabel the data points in such a way that $P$ becomes an almost block matrix. In this form, the ratios of the off-diagonal block entries to the diagonal block entries become negligible, on the order of $\\delta\\ll1$, as depicted in Fig.~\\ref{fig:method3}(a). The diagonal blocks of $P$ correspond to clusters of strongly connected vertices in the graph representation Fig~\\ref{fig:method2}(b).\n",
    "\n",
    "Furthermore, the spectrum of $P$, being a doubly stochastic matrix, includes an eigenvalue $\\lambda_1=1$. Additionally, there exist $k-1$ dominant eigenvalues $\\lambda_k\\sim\\mathcal{O}(1)$, where $k$ represents the number of clusters in the graph, tipically satisfying $k\\ll n$. The remaining eigenvalues are separated by a spectral gap $\\Delta\\lambda$, such that $1-\\Delta\\lambda\\ll1$ [Fig.~\\ref{fig:method3}(b)]. By expressing the delta peaked distribution $\\mathbf{e}_i$ as a linear combination of the eigenfunctions, $\\psi_j$, of $P$, we obtain the following approximation:\n",
    "\\begin{equation}\n",
    "Z_{i}^{m}\\sim\\sum_{j=1}^{N}{\\lambda_j^m\\frac{\\psi_{j,i}}{|\\psi_{j}|^2}\\psi_{j}}=\\sum_{j=1}^{k}{\\lambda_j^m\\frac{\\psi_{j,i}}{|\\psi_{j}|^2}\\psi_{j}}+\\mathcal{O}(\\delta^m).\n",
    "\\end{equation}\n",
    "For sufficiently long times, the probability that the trajectory $\\mathcal{Z}$ residing within the linear span of the dominant eigenfunctions, $\\mathcal{L}^{k}=\\left\\langle\\{\\psi_i\\}_{i=2}^{k}\\right\\rangle$, becomes exceedingly high, as $\\delta^m\\lll1$. This observation permits the interpretation of the eigenfunctions $\\psi_j$ as the slow variables governing the fictitious diffusion process. Given that $\\mathcal{Z}$ closely approximates the actual trajectory $\\mathcal{Y}$, we identify $\\{\\psi_j\\}_{i=2}^{k}$ as the slow variables of the collective system. Notably, we exclude the first eigenfunction due to its constant value across all data point $Y_i$, therefore the effective dimensionality of the system is $k-1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's calculate the distance matrix\n",
    "\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "distance_matrix = cdist(moment_features, moment_features, 'euclidean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we calculate the transition matrix and the diffusion coordinates\n",
    "from scipy.sparse.linalg import eigsh\n",
    "def DiffMap(D, epsilon, maxoutdim=10):\n",
    "    \"\"\"\n",
    "    Computes the diffusion map embedding of a distance matrix D.\n",
    "\n",
    "    Args:\n",
    "        D (numpy.ndarray): The pairwise distance matrix.\n",
    "        epsilon (float): The kernel bandwidth parameter.\n",
    "        maxoutdim (int, optional): The maximum number of output dimensions. Defaults to 2.\n",
    "        maxiter (int, optional): The maximum number of iterations for the eigensolver. Defaults to 1000.\n",
    "\n",
    "    Returns:\n",
    "        L (numpy.ndarray): The row-normalized Laplacian matrix.\n",
    "        lambdas (numpy.ndarray): The eigenvalues in descending order.\n",
    "        eigenvectors (numpy.ndarray): The corresponding eigenvectors.\n",
    "        Y (numpy.ndarray): The diffusion map embedding.\n",
    "    \"\"\"\n",
    "    Dmax = np.max(D) #Normalize the distance matrix, doing this we can limit epsilon to the interval [0,1]\n",
    "    K = np.exp(-(D ** 2) / (Dmax ** 2 * epsilon))\n",
    "\n",
    "    # Efficiently normalize K (avoiding matrix inversion)\n",
    "    row_sums = np.sum(K, axis=1)  \n",
    "    L = K / row_sums[:, np.newaxis]  \n",
    "\n",
    "    # Solve for the k largest eigenvalues\n",
    "    e_vals, e_vecs = eigsh(L,k = maxoutdim, which='LM', ncv = 2*maxoutdim+1)\n",
    "\n",
    "    # Calculate the diffusion map embedding\n",
    "    modes = e_vecs * e_vals\n",
    "\n",
    "    return L, e_vecs, e_vals, modes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Typically epsilon ~ 0.05 works well in most cases for a better choice see the next section\n",
    "epsilon = 0.05\n",
    "max_number_mode = 20\n",
    "transition_matrix, e_vals, e_vecs, modes = DiffMap(distance_matrix, epsilon, max_number_mode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure style=\"display: flex; flex-direction:column; justify-content: center; align-items: center; gap: 20px\">\n",
    "    <img style=\"width: 16cm; background-color: white\" src = \"./method03.png\" />\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Identification of coarse-grain variables through spectral analysis of the transition matrix. (a) Transitions between states within the same cluster will generally be more likely than transitions between states across clusters. This is apparent in both the block-like structure of $P_{\\epsilon}$ and its spectrum (b). Each block along the diagonal of $P_{\\epsilon}$ corresponds to a different cluster. (b) Due to the doubly stochastic nature of $P$, the largest eigenvalue will always be $\\lambda_1=1$, the rest of the eigenvalues can be ordered as follows $\\lambda_{j+1}\\leq\\lambda_j<\\lambda_1$. The time spent on each cluster is inversely proportional to $1-\\lambda_j\\sim\\ll1$, for $j=2,3,\\ldots,k$, where $k$ is the number of clusters. According to Eq.\\eqref{eq:diffmap_01}, we can identify $k$, by looking for a spectral gap $\\Delta\\lambda$. (c) Trajectories $\\mathcal{Z}=\\{Z_i\\}_{i=1}^N$ (black solid line) generated through iterative application of $P_{\\epsilon}$ approximate the collective dynamics of the real trajectory $\\mathcal{Y}=\\{Y_i\\}_{i=1}^N$ (blue dotted line). We can therefore interpret the eigenvectors with slow dynamics, as the collective variables, or order parameters of the system. For the zebra fish data set in Fig.\\ref{fig:method1}, there is a single non-trivial eigenvalue (see Sec.~\\ref{subsec: schooling}) with associated eigenvector $\\psi_2$. This eigenvector points from the swirling state with positive angular momentum $X_+$ (anticlockwise rotation) to the state with negative angular momentum $X_-$ (clockwise rotation). (d) The projections along the dominant eigenvectors (diffusion coordinates) reveal symmetry-breaking states. Note that the projections concentrate around $X_{\\pm}$, indeed the density of states (gray curve) is higher around the attractors. (e) Projecting a trajectory onto the diffusion coordinates generates a time series $\\psi_2(t)$ from which the coarse-grain dynamics, that is the dynamics of the order parameter $\\Phi(t)$, can be inferred.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now before looking at the results, we should ask ourselves what do we expect the spectrum of the diffusion map to look like. According to our argument above. The eigenvectors of the diffusion map correspond to the slow variables of the system or the collective variables. In the case of zebra fish, experiments have shown that if a group of zebra fish consist of juvenile (younger than one year), the group tend to form what is know as a \"school\", which is a collective state in which the individuals align with each other. In physics we call these a polarized state, which is characterized by an average orientation of constant magnitude. Denoting by $\\mathbf{n}_i$ the orientation of the $i$-th fish, we define the polarization as\n",
    "\\begin{equation}\n",
    "\\varphi=\\left|\\left\\langle\\mathbf{n}_i\\right\\rangle\\right|=\\frac{1}{n}\\left|\\sum_{i=1}^{n}{\\mathbf{n}_i(t)}\\right| = Const.\n",
    "\\end{equation}\n",
    "Note that, this does not mean that the orientation of the group is constant, only it's magnitude remains constant in the steady state. This means that the group as a whole can change its orientation but it the individuals will remain aligned. With this in mind we can now guess the result of the diffusion map, we should see two dominant eigenvalues on the spectrum, corresponding to the components of the polarization vector, Let's see if this is the case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(np.arange(len(e_vecs)),e_vecs[::-1])\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('$\\\\lambda_k$')\n",
    "plt.xticks(np.arange(len(e_vecs),step=2))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly, there is only one dominant eigenvalue. What could be happening? Well for that we need to visualize the data, here is an animation of the trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"https://www.youtube.com/watch?v=NOqUXRsFo9Q\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Video\n",
    "Video(\"https://youtu.be/NOqUXRsFo9Q\")\n",
    "# Video(\"https://www.youtube.com/watch?v=NOqUXRsFo9Q\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see the fish do align but they are constrained to move in a circular tank, therefore the group remains unpolarized, instead it swirls around the the tank. The time series in the bottom plot shows the polarization in yellow, which fluctuates rapidly around 0. The blue curve on the other hand, shows the average angular velocity. As we can see, the fluctuation are much smaller and its overall dynamics is slower than that of the individual fish. Based on this observations, we can guess that the slow mode that we obtained from the diffusion map is actually the average angular velocity. To show that this is indeed the case we take the projections of the data points onto the second eigenvector, which are the components of $\\psi_2$ and compare each one of them to their corresponding angular velocity\n",
    "\\begin{equation}\n",
    "L_i = \\left\\langle \\mathbf{x}_i\\times\\mathbf{v}_i\\right\\rangle = \\frac{1}{n}\\sum_{i=1}^{n}{\\mathbf{x}_i\\times\\mathbf{v}_i}.\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We can extract the angular momentum from the components of the feature vectors\n",
    "angular_velocity = moment_features[7]-moment_features[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now let's plot the angular velocity against the second mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upon identifying these slow variables, we proceed to characterize the coarse-grain dynamics of the system, by projecting the trajectory $\\mathcal{Y}$ onto $\\mathcal{L}^{k}$ [Fig.~\\ref{fig:method3}(d)]. This process generates $k-1$ time series $\\{\\{\\psi_{j,i}\\}_{i=1}^{N}\\}_{j=2}^{k}$, that can then be employed to learn a dynamical system that captures the essential behavior of the system [Fig.~\\ref{fig:method}(e)]. We refer to this dynamical system as the \"coarse-grain dynamics\" of the collective. In certain scenarios, it might be feasible to derive Langevin-like equations of motion that describe the evolution of these coarse-grain variables. In essence, this process effectively uncovers the mean field theory of the collective system.\n",
    "\n",
    "The method above can also be used to identify phase transitions, when they exist. Indeed, in some cases we can change the geometry of the phase space by tuning control parameters, for example temperature, density or noise intensity. In many cases, a collective system will lack a slow manifold when the control parameters are above a certain threshold, therefore the data points will be, roughly, evenly distributed over the whole space and the diffusion map will not be able to identify any cluster. This is reflected on the spectrum of $P_{\\epsilon}$ which now has a spectral gap between $\\lambda_1$ and $\\lambda_2$ (see below).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "text_representation": {
    "extension": ".md",
    "format_name": "myst",
    "format_version": "0.13",
    "jupytext_version": "1.14.5"
   }
  },
  "kernelspec": {
   "display_name": "diffmap-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
